{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zipped_pickle(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        loaded_object = pickle.load(f)\n",
    "        return loaded_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_zipped_pickle(obj, filename):\n",
    "    with gzip.open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, 2)\n",
    "        \n",
    "def flatten(dicts):\n",
    "    \n",
    "    # extract the annotated video frames, their labels\n",
    "    # and the boxes\n",
    "    \n",
    "    images = []\n",
    "    boxes = []\n",
    "    labels = []\n",
    "    \n",
    "    for i, dic in enumerate(dicts):\n",
    "        \n",
    "        video = dic['video']\n",
    "        frames = dic['frames']\n",
    "        dic_labels = dic['label']\n",
    "        \n",
    "        images.append((video[:,:,frames[0]] / 255).astype('float32'))\n",
    "        images.append((video[:,:,frames[1]] / 255).astype('float32'))\n",
    "        images.append((video[:,:,frames[2]] / 255).astype('float32'))\n",
    "        \n",
    "        labels.append(dic_labels[:,:,frames[0]].astype('uint8'))\n",
    "        labels.append(dic_labels[:,:,frames[1]].astype('uint8'))\n",
    "        labels.append(dic_labels[:,:,frames[2]].astype('uint8'))\n",
    "        \n",
    "        boxes.append(dic['box'].astype('uint8'))\n",
    "        boxes.append(dic['box'].astype('uint8'))\n",
    "        boxes.append(dic['box'].astype('uint8'))\n",
    "        \n",
    "    return images, boxes, labels\n",
    "\n",
    "def resize(images, boxes, labels, size):\n",
    "    \n",
    "    # resize images, boxes and labels\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        \n",
    "        images[i] = cv2.resize(images[i], size, interpolation = cv2.INTER_LANCZOS4)\n",
    "        boxes[i] = cv2.resize(boxes[i], size, interpolation = cv2.INTER_LANCZOS4)\n",
    "        labels[i] = cv2.resize(labels[i], size, interpolation = cv2.INTER_LANCZOS4)\n",
    "        \n",
    "        # add number of channels (in this case 1) at the front for the\n",
    "        # right input shape for the pytorch layers\n",
    "        \n",
    "        images[i] = np.expand_dims(images[i], axis=0)\n",
    "        images[i] = np.expand_dims(images[i], axis=0)\n",
    "        \n",
    "        labels[i] = np.expand_dims(labels[i], axis=0)\n",
    "        \n",
    "    return np.concatenate(images, axis=0), boxes, np.concatenate(labels, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_data = load_zipped_pickle(\"data/train.pkl\")\n",
    "test_data = load_zipped_pickle(\"data/test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (128, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, boxes, labels = flatten(train_data)\n",
    "images, boxes, labels = resize(images, boxes, labels, size)\n",
    "\n",
    "train_images = torch.from_numpy(images[194:]).to(device)\n",
    "labels = torch.from_numpy(labels[194:]).to(device)\n",
    "# TODO: add data augmentation, denoising, other preprocessing steps?\n",
    "# TODO: split into train and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    \n",
    "    def __init__(self, filters=64):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.max_pool = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.block_enc_1 = self.conv_block(1, filters)\n",
    "        self.block_enc_2 = self.conv_block(filters, 2*filters)\n",
    "        self.block_enc_3 = self.conv_block(2*filters, 4*filters)\n",
    "        \n",
    "        self.block_inbetween = self.conv_block(4*filters, 8*filters, True)\n",
    "        \n",
    "        self.block_dec_1 = self.conv_block(8*filters, 4*filters, True)\n",
    "        self.block_dec_2 = self.conv_block(4*filters, 2*filters, True)\n",
    "        \n",
    "        self.block_last = self.conv_block(2*filters, filters, True, True)\n",
    "        \n",
    "    def conv_block(self, channels, filters, enc=False, last=False):\n",
    "        \n",
    "        modules = []\n",
    "        \n",
    "        modules.append(nn.Conv2d(channels, filters, 3, 1, padding='same'))\n",
    "        modules.append(nn.ReLU())\n",
    "        modules.append(nn.Conv2d(filters, filters, 3, 1, padding='same'))\n",
    "        modules.append(nn.ReLU())\n",
    "\n",
    "        if enc:\n",
    "            if not last:\n",
    "                modules.append(nn.ConvTranspose2d(filters, filters//2, 2, stride=2))\n",
    "            else:\n",
    "                modules.append(nn.Conv2d(filters, 1, 1, 1))\n",
    "                modules.append(nn.Sigmoid())\n",
    "            \n",
    "        return nn.Sequential(*modules)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # encoder\n",
    "        \n",
    "        x1 = self.block_enc_1(x)\n",
    "        x2 = self.max_pool(x1)\n",
    "        \n",
    "        x3 = self.block_enc_2(x2)\n",
    "        x4 = self.max_pool(x3)\n",
    "        \n",
    "        x5 = self.block_enc_3(x4)\n",
    "        x6 = self.max_pool(x5)\n",
    "        \n",
    "        # between encoder and decoder\n",
    "        \n",
    "        x7 = self.block_inbetween(x6)\n",
    "        \n",
    "        # decoder\n",
    "        \n",
    "        x8 = self.block_dec_1(torch.cat((x7, x5), dim=1))\n",
    "        x9 = self.block_dec_2(torch.cat((x8, x3), dim=1))\n",
    "        \n",
    "        x10 = self.block_last(torch.cat((x9, x1), dim=1))\n",
    "        \n",
    "        return x10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(inputs, targets):       \n",
    "        \n",
    "        inputs = inputs.squeeze()\n",
    "        inputs = torch.round(inputs).to(torch.uint8)\n",
    "        \n",
    "        intersection = (inputs * targets).sum(dim=(1, 2))\n",
    "        total = (inputs + targets).sum(dim=(1, 2))\n",
    "        union = total - intersection \n",
    "        \n",
    "        IoU = intersection / union\n",
    "                \n",
    "        return IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (3965556404.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [153]\u001b[1;36m\u001b[0m\n\u001b[1;33m    # TODO: calculate IoU for validation dataset\u001b[0m\n\u001b[1;37m                                                ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def val_loss(model, val_loader):\n",
    "    # TODO: calculate IoU for validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = Unet(filters=16).to(device)\n",
    "optimizer = torch.optim.Adam(unet.parameters(), lr=1e-3)\n",
    "criterion = smp.losses.JaccardLoss(mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensorset = TensorDataset(train_images, labels)\n",
    "train_loader = DataLoader(train_tensorset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train IoU: 0.0419 | Train loss: 0.9937 |  Duration 0.23 sec\n",
      "Epoch 1 | Train IoU: 0.0419 | Train loss: 0.9937 |  Duration 0.28 sec\n",
      "Epoch 2 | Train IoU: 0.0419 | Train loss: 0.9937 |  Duration 0.26 sec\n",
      "Epoch 3 | Train IoU: 0.0419 | Train loss: 0.9937 |  Duration 0.23 sec\n",
      "Epoch 4 | Train IoU: 0.0419 | Train loss: 0.9937 |  Duration 0.25 sec\n",
      "Epoch 5 | Train IoU: 0.0419 | Train loss: 0.9937 |  Duration 0.27 sec\n",
      "Epoch 6 | Train IoU: 0.0419 | Train loss: 0.9937 |  Duration 0.24 sec\n",
      "Epoch 7 | Train IoU: 0.0419 | Train loss: 0.9937 |  Duration 0.26 sec\n",
      "Epoch 8 | Train IoU: 0.0419 | Train loss: 0.9937 |  Duration 0.26 sec\n",
      "Epoch 9 | Train IoU: 0.0419 | Train loss: 0.9937 |  Duration 0.29 sec\n",
      "Epoch 10 | Train IoU: 0.0419 | Train loss: 0.9937 |  Duration 0.26 sec\n",
      "Epoch 11 | Train IoU: 0.0419 | Train loss: 0.9937 |  Duration 0.26 sec\n",
      "Epoch 12 | Train IoU: 0.0419 | Train loss: 0.9937 |  Duration 0.25 sec\n",
      "Epoch 13 | Train IoU: 0.0419 | Train loss: 0.9936 |  Duration 0.27 sec\n",
      "Epoch 14 | Train IoU: 0.0419 | Train loss: 0.9936 |  Duration 0.26 sec\n",
      "Epoch 15 | Train IoU: 0.0419 | Train loss: 0.9936 |  Duration 0.29 sec\n",
      "Epoch 16 | Train IoU: 0.0419 | Train loss: 0.9936 |  Duration 0.29 sec\n",
      "Epoch 17 | Train IoU: 0.0419 | Train loss: 0.9936 |  Duration 0.30 sec\n",
      "Epoch 18 | Train IoU: 0.0419 | Train loss: 0.9936 |  Duration 0.23 sec\n",
      "Epoch 19 | Train IoU: 0.0419 | Train loss: 0.9936 |  Duration 0.26 sec\n",
      "Epoch 20 | Train IoU: 0.0419 | Train loss: 0.9936 |  Duration 0.26 sec\n",
      "Epoch 21 | Train IoU: 0.0419 | Train loss: 0.9936 |  Duration 0.24 sec\n",
      "Epoch 22 | Train IoU: 0.0419 | Train loss: 0.9935 |  Duration 0.28 sec\n",
      "Epoch 23 | Train IoU: 0.0419 | Train loss: 0.9935 |  Duration 0.25 sec\n",
      "Epoch 24 | Train IoU: 0.0419 | Train loss: 0.9935 |  Duration 0.29 sec\n",
      "Epoch 25 | Train IoU: 0.0419 | Train loss: 0.9934 |  Duration 0.28 sec\n",
      "Epoch 26 | Train IoU: 0.0419 | Train loss: 0.9934 |  Duration 0.24 sec\n",
      "Epoch 27 | Train IoU: 0.0419 | Train loss: 0.9933 |  Duration 0.32 sec\n",
      "Epoch 28 | Train IoU: 0.0419 | Train loss: 0.9933 |  Duration 0.24 sec\n",
      "Epoch 29 | Train IoU: 0.0419 | Train loss: 0.9932 |  Duration 0.24 sec\n",
      "Epoch 30 | Train IoU: 0.0419 | Train loss: 0.9931 |  Duration 0.24 sec\n",
      "Epoch 31 | Train IoU: 0.0419 | Train loss: 0.9930 |  Duration 0.29 sec\n",
      "Epoch 32 | Train IoU: 0.0419 | Train loss: 0.9929 |  Duration 0.25 sec\n",
      "Epoch 33 | Train IoU: 0.0419 | Train loss: 0.9929 |  Duration 0.31 sec\n",
      "Epoch 34 | Train IoU: 0.0419 | Train loss: 0.9928 |  Duration 0.27 sec\n",
      "Epoch 35 | Train IoU: 0.0419 | Train loss: 0.9927 |  Duration 0.30 sec\n",
      "Epoch 36 | Train IoU: 0.0419 | Train loss: 0.9927 |  Duration 0.26 sec\n",
      "Epoch 37 | Train IoU: 0.0419 | Train loss: 0.9926 |  Duration 0.23 sec\n",
      "Epoch 38 | Train IoU: 0.0419 | Train loss: 0.9926 |  Duration 0.24 sec\n",
      "Epoch 39 | Train IoU: 0.0419 | Train loss: 0.9924 |  Duration 0.28 sec\n",
      "Epoch 40 | Train IoU: 0.0419 | Train loss: 0.9931 |  Duration 0.22 sec\n",
      "Epoch 41 | Train IoU: 0.0419 | Train loss: 0.9923 |  Duration 0.24 sec\n",
      "Epoch 42 | Train IoU: 0.0419 | Train loss: 0.9924 |  Duration 0.24 sec\n",
      "Epoch 43 | Train IoU: 0.0419 | Train loss: 0.9925 |  Duration 0.29 sec\n",
      "Epoch 44 | Train IoU: 0.0419 | Train loss: 0.9924 |  Duration 0.24 sec\n",
      "Epoch 45 | Train IoU: 0.0419 | Train loss: 0.9923 |  Duration 0.27 sec\n",
      "Epoch 46 | Train IoU: 0.0419 | Train loss: 0.9921 |  Duration 0.29 sec\n",
      "Epoch 47 | Train IoU: 0.0419 | Train loss: 0.9921 |  Duration 0.28 sec\n",
      "Epoch 48 | Train IoU: 0.0419 | Train loss: 0.9919 |  Duration 0.27 sec\n",
      "Epoch 49 | Train IoU: 0.0419 | Train loss: 0.9920 |  Duration 0.25 sec\n",
      "Epoch 50 | Train IoU: 0.0419 | Train loss: 0.9920 |  Duration 0.24 sec\n",
      "Epoch 51 | Train IoU: 0.0419 | Train loss: 0.9919 |  Duration 0.25 sec\n",
      "Epoch 52 | Train IoU: 0.0419 | Train loss: 0.9918 |  Duration 0.27 sec\n",
      "Epoch 53 | Train IoU: 0.0419 | Train loss: 0.9916 |  Duration 0.23 sec\n",
      "Epoch 54 | Train IoU: 0.0419 | Train loss: 0.9918 |  Duration 0.20 sec\n",
      "Epoch 55 | Train IoU: 0.0419 | Train loss: 0.9915 |  Duration 0.22 sec\n",
      "Epoch 56 | Train IoU: 0.0419 | Train loss: 0.9916 |  Duration 0.23 sec\n",
      "Epoch 57 | Train IoU: 0.0419 | Train loss: 0.9916 |  Duration 0.25 sec\n",
      "Epoch 58 | Train IoU: 0.0419 | Train loss: 0.9915 |  Duration 0.30 sec\n",
      "Epoch 59 | Train IoU: 0.0419 | Train loss: 0.9914 |  Duration 0.32 sec\n",
      "Epoch 60 | Train IoU: 0.0419 | Train loss: 0.9914 |  Duration 0.28 sec\n",
      "Epoch 61 | Train IoU: 0.0419 | Train loss: 0.9913 |  Duration 0.24 sec\n",
      "Epoch 62 | Train IoU: 0.0419 | Train loss: 0.9913 |  Duration 0.27 sec\n",
      "Epoch 63 | Train IoU: 0.0419 | Train loss: 0.9913 |  Duration 0.23 sec\n",
      "Epoch 64 | Train IoU: 0.0419 | Train loss: 0.9912 |  Duration 0.19 sec\n",
      "Epoch 65 | Train IoU: 0.0419 | Train loss: 0.9914 |  Duration 0.23 sec\n",
      "Epoch 66 | Train IoU: 0.0419 | Train loss: 0.9913 |  Duration 0.23 sec\n",
      "Epoch 67 | Train IoU: 0.0419 | Train loss: 0.9914 |  Duration 0.28 sec\n",
      "Epoch 68 | Train IoU: 0.0419 | Train loss: 0.9914 |  Duration 0.23 sec\n",
      "Epoch 69 | Train IoU: 0.0419 | Train loss: 0.9914 |  Duration 0.29 sec\n",
      "Epoch 70 | Train IoU: 0.0419 | Train loss: 0.9913 |  Duration 0.29 sec\n",
      "Epoch 71 | Train IoU: 0.0419 | Train loss: 0.9911 |  Duration 0.27 sec\n",
      "Epoch 72 | Train IoU: 0.0419 | Train loss: 0.9914 |  Duration 0.33 sec\n",
      "Epoch 73 | Train IoU: 0.0419 | Train loss: 0.9911 |  Duration 0.26 sec\n",
      "Epoch 74 | Train IoU: 0.0419 | Train loss: 0.9913 |  Duration 0.31 sec\n",
      "Epoch 75 | Train IoU: 0.0419 | Train loss: 0.9913 |  Duration 0.31 sec\n",
      "Epoch 76 | Train IoU: 0.0419 | Train loss: 0.9913 |  Duration 0.36 sec\n",
      "Epoch 77 | Train IoU: 0.0419 | Train loss: 0.9912 |  Duration 0.40 sec\n",
      "Epoch 78 | Train IoU: 0.0419 | Train loss: 0.9914 |  Duration 0.80 sec\n",
      "Epoch 79 | Train IoU: 0.0419 | Train loss: 0.9912 |  Duration 0.50 sec\n",
      "Epoch 80 | Train IoU: 0.0419 | Train loss: 0.9912 |  Duration 0.54 sec\n",
      "Epoch 81 | Train IoU: 0.0419 | Train loss: 0.9912 |  Duration 0.47 sec\n",
      "Epoch 82 | Train IoU: 0.0419 | Train loss: 0.9912 |  Duration 0.53 sec\n",
      "Epoch 83 | Train IoU: 0.0419 | Train loss: 0.9911 |  Duration 0.62 sec\n",
      "Epoch 84 | Train IoU: 0.0419 | Train loss: 0.9911 |  Duration 0.68 sec\n",
      "Epoch 85 | Train IoU: 0.0419 | Train loss: 0.9910 |  Duration 0.55 sec\n",
      "Epoch 86 | Train IoU: 0.0419 | Train loss: 0.9910 |  Duration 0.56 sec\n",
      "Epoch 87 | Train IoU: 0.0419 | Train loss: 0.9910 |  Duration 0.86 sec\n",
      "Epoch 88 | Train IoU: 0.0419 | Train loss: 0.9910 |  Duration 1.44 sec\n",
      "Epoch 89 | Train IoU: 0.0419 | Train loss: 0.9910 |  Duration 1.40 sec\n",
      "Epoch 90 | Train IoU: 0.0419 | Train loss: 0.9910 |  Duration 1.34 sec\n",
      "Epoch 91 | Train IoU: 0.0419 | Train loss: 0.9911 |  Duration 1.45 sec\n",
      "Epoch 92 | Train IoU: 0.0419 | Train loss: 0.9909 |  Duration 1.42 sec\n",
      "Epoch 93 | Train IoU: 0.0419 | Train loss: 0.9909 |  Duration 1.27 sec\n",
      "Epoch 94 | Train IoU: 0.0419 | Train loss: 0.9910 |  Duration 1.05 sec\n",
      "Epoch 95 | Train IoU: 0.0419 | Train loss: 0.9910 |  Duration 1.18 sec\n",
      "Epoch 96 | Train IoU: 0.0419 | Train loss: 0.9910 |  Duration 1.11 sec\n",
      "Epoch 97 | Train IoU: 0.0419 | Train loss: 0.9910 |  Duration 1.12 sec\n",
      "Epoch 98 | Train IoU: 0.0419 | Train loss: 0.9909 |  Duration 1.10 sec\n",
      "Epoch 99 | Train IoU: 0.0419 | Train loss: 0.9909 |  Duration 1.17 sec\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    \n",
    "    t = time.time()\n",
    "    num_samples_epoch = 0\n",
    "    train_loss_cum = 0\n",
    "    IoU = torch.Tensor()\n",
    "    \n",
    "    for x,y in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        unet.train()\n",
    "        output = unet(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # keep track of training loss\n",
    "        num_samples_epoch += x.shape[0]\n",
    "        train_loss_cum += loss * x.shape[0]\n",
    "        \n",
    "        # need the median IoU\n",
    "        unet.eval()\n",
    "        with torch.no_grad():\n",
    "            IoU = torch.cat((IoU, iou(x, y)))\n",
    "        \n",
    "    train_iou = torch.median(IoU)\n",
    "    train_loss = train_loss_cum / num_samples_epoch\n",
    "        \n",
    "    epoch_duration = time.time() - t\n",
    "    \n",
    "    print(f'Epoch {epoch} | Train IoU: {train_iou:.4f} | '\n",
    "          f'Train loss: {train_loss:.4f} | '\n",
    "          #f' Validation loss: {val_loss:.4f} | '\n",
    "          f' Duration {epoch_duration:.2f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = unet(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = iou(res, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.median(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "586f7db3c72cdbd2111a5fe733ffa252a59827d1d7df0e37a9fca40f971001cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
