{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "0b5b2a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.linear_model import Ridge, Lasso, HuberRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import mixture\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.cluster import DBSCAN\n",
    "import itertools\n",
    "from scipy import linalg\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "eab07b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"X_train.csv\")\n",
    "X = X.drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "53fa0e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv(\"y_train.csv\")['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "46376665",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "ids = X_test[\"id\"]\n",
    "X_test = X_test.drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1329bd54",
   "metadata": {},
   "source": [
    "Remove constant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "80ead9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1212, 828)"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.loc[:, X.var() != 0.0]\n",
    "X = X.loc[:, X.var() != 0.0]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3788f36",
   "metadata": {},
   "source": [
    "Impute median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "d131c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = (X_test - X.mean()) / X.std()\n",
    "X = (X - X.mean()) / X.std ()\n",
    "X = X.fillna(X.median())\n",
    "X_test = X_test.fillna(X.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "54fcfce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7aa2cb",
   "metadata": {},
   "source": [
    "Truncate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "fd060405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate(train, test, delta=0.01):\n",
    "    \n",
    "    bot = X.quantile(delta)\n",
    "    top = X.quantile(1-delta)\n",
    "    \n",
    "    for column in train.columns:\n",
    "        train.loc[train[column] < bot[column], column] = train[column].median()\n",
    "        train.loc[train[column] > top[column], column] = train[column].median()\n",
    "        test.loc[test[column] < bot[column], column] = train[column].median()\n",
    "        test.loc[test[column] > top[column], column] = train[column].median()\n",
    "        \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "6767566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe(train, val, target, n=20):\n",
    "    \n",
    "    estimator = Ridge(alpha=5)\n",
    "    selector = RFE(estimator, n_features_to_select=n, step=5, verbose=0)\n",
    "    selector = selector.fit(train, target)\n",
    "    train = selector.transform(train)\n",
    "    val = selector.transform(val)\n",
    "    \n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402832d3",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "75502a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(train, val, n=20):\n",
    "    \n",
    "    pca = KernelPCA(kernel='rbf', n_components=n)\n",
    "    train_t = pca.fit_transform(train)\n",
    "    val_t = pca.transform(val)\n",
    "    \n",
    "    return train_t, val_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "39ec702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_select(train, val, target, alpha=1):\n",
    "    \n",
    "    clf = Lasso(alpha=alpha)\n",
    "    clf.fit(train, target)\n",
    "    train = train[:,clf.coef_ != 0]\n",
    "    val = val[:, clf.coef_ != 0]\n",
    "    print(\"Selected features: \" ,np.count_nonzero(clf.coef_))\n",
    "    \n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "34931133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sel_best(train, val, target, n=20):\n",
    "    \n",
    "    sel = SelectKBest(f_regression, k=n)\n",
    "    train_t = sel.fit_transform(train, target)\n",
    "    val_t = sel.transform(val)\n",
    "    \n",
    "    return train_t, val_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed7c8e5",
   "metadata": {},
   "source": [
    "Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "b9c3f883",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = copy.copy(X)\n",
    "X_test_t = X_test.to_numpy()\n",
    "mask = np.arange(X_t.shape[0])\n",
    "np.random.shuffle(mask)\n",
    "X_t = X_t[mask]\n",
    "y_t = y[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "1a862b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:  18\n",
      "Removed outliers:  49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richard\\miniconda3\\envs\\pytcu10\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:  21\n",
      "Removed outliers:  49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richard\\miniconda3\\envs\\pytcu10\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:  18\n",
      "Removed outliers:  49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richard\\miniconda3\\envs\\pytcu10\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:  21\n",
      "Removed outliers:  49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richard\\miniconda3\\envs\\pytcu10\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:  18\n",
      "Removed outliers:  49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richard\\miniconda3\\envs\\pytcu10\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "step = X.shape[0] // 5\n",
    "r2_val_ridge, r2_train_ridge = 0, 0\n",
    "r2_val_xgb, r2_train_xgb = 0, 0\n",
    "r2_val_lasso, r2_train_lasso = 0, 0\n",
    "r2_val_gbr, r2_train_gbr = 0, 0\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    X_val, y_val = X_t[i*step:(i+1)*step], y_t[i*step:(i+1)*step]\n",
    "    X_train = np.concatenate((X_t[(i+1)*step:], X_t[:i*step]), axis=0)\n",
    "    y_train = np.concatenate((y_t[(i+1)*step:], y_t[:i*step]), axis=0)\n",
    "    \n",
    "    # X_train, X_val = rfe(X_train, X_val, y_train, n=20)\n",
    "    \n",
    "    # feature selection\n",
    "    \n",
    "    X_train, X_val = lasso_select(X_train, X_val, y_train, alpha=0.8)\n",
    "\n",
    "    # fit gmm and remove 0.05 quantile of the loglikelihood scores\n",
    "    gmm = mixture.GaussianMixture(n_components=1, covariance_type='full')\n",
    "    gmm.fit(np.concatenate((X_train, np.expand_dims(y_train, axis=-1)), axis=-1))\n",
    "    loglike = gmm.score_samples(np.concatenate((X_train, np.expand_dims(y_train, axis=-1)), axis=-1))\n",
    "    cutoff = np.quantile(loglike, 0.05)\n",
    "    print(\"Removed outliers: \", X_train.shape[0] - (loglike > cutoff).sum())\n",
    "    X_train = X_train[loglike > cutoff]\n",
    "    y_train = y_train[loglike > cutoff]\n",
    "    \n",
    "    # X_train, X_val = sel_best(X_train, X_val, y_train, n=100)\n",
    "    # X_train, X_val = pca(X_train, X_val, n=30)\n",
    "    \n",
    "    ridge = Ridge(alpha=2)\n",
    "    # xgb = XGBRegressor(max_depth=2, reg_lambda=200)\n",
    "    lasso = Lasso(alpha=1)\n",
    "    gbr = GradientBoostingRegressor(max_depth=2, learning_rate=0.03, n_estimators=400)\n",
    "    \n",
    "    ridge.fit(X_train, y_train)\n",
    "    # xgb.fit(X_train, y_train)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    gbr.fit(X_train, y_train)\n",
    "    \n",
    "    r2_val_ridge += r2_score(y_val, ridge.predict(X_val))\n",
    "    # r2_val_xgb += r2_score(y_val, xgb.predict(X_val))\n",
    "    r2_val_lasso += r2_score(y_val, lasso.predict(X_val))\n",
    "    r2_val_gbr += r2_score(y_val, gbr.predict(X_val))\n",
    "    \n",
    "    r2_train_ridge += r2_score(y_train, ridge.predict(X_train))\n",
    "    # r2_train_xgb += r2_score(y_train, xgb.predict(X_train))\n",
    "    r2_train_lasso += r2_score(y_train, lasso.predict(X_train))\n",
    "    r2_train_gbr += r2_score(y_train, gbr.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44681380",
   "metadata": {},
   "source": [
    "Validation Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "d69c1010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge:  0.3089440569439783\n",
      "Lasso:  0.31046257598656785\n",
      "GBR: 0.43197724031539486\n"
     ]
    }
   ],
   "source": [
    "print(\"Ridge: \", r2_val_ridge/5)\n",
    "# print(\"XBG: \", r2_val_xgb/5)\n",
    "print(\"Lasso: \", r2_val_lasso/5)\n",
    "print(\"GBR:\", r2_val_gbr/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab699091",
   "metadata": {},
   "source": [
    "Train Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "ff0d7b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge:  0.5203651558907085\n",
      "Lasso:  0.4478652472832977\n",
      "GBR: 0.7527813576639846\n"
     ]
    }
   ],
   "source": [
    "print(\"Ridge: \", r2_train_ridge/5)\n",
    "# print(\"XBG: \", r2_train_xgb/5)\n",
    "print(\"Lasso: \", r2_train_lasso/5)\n",
    "print(\"GBR:\", r2_train_gbr/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d040cb7",
   "metadata": {},
   "source": [
    "Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81b8ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t_s, X_test_s = lasso_select(X_t, X_test_t, y_t, alpha=1)\n",
    "gbr = GradientBoostingRegressor(max_depth=2, learning_rate=0.03, n_estimators=400)\n",
    "gmm = mixture.GaussianMixture(n_components=2, covariance_type='full')\n",
    "gmm.fit(np.concatenate((X_t_s, np.expand_dims(y_t, axis=-1)), axis=-1))\n",
    "loglike = gmm.score_samples(np.concatenate((X_t_s, np.expand_dims(y_t, axis=-1)), axis=-1))\n",
    "cutoff = np.quantile(loglike, 0.05)\n",
    "print(X_t_s.shape[0] - (loglike > cutoff).sum())\n",
    "X_t_s = X_t_s[loglike > cutoff]\n",
    "y_t = y_t[loglike > cutoff]\n",
    "gbr.fit(X_t_s, y_t)\n",
    "sub = gbr.predict(X_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b024dd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"id\": ids, \"y\": sub}).to_csv(\"sub_gbr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3ccef8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
