{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5abe9fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from ignite.contrib.metrics.regression import R2Score\n",
    "import time\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eab07b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"X_train.csv\")\n",
    "X = X.drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53fa0e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv(\"y_train.csv\")['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "46376665",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "ids = X_test[\"id\"]\n",
    "X_test = X_test.drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1329bd54",
   "metadata": {},
   "source": [
    "Remove constant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "80ead9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.loc[:, X.var() != 0.0]\n",
    "X = X.loc[:, X.var() != 0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a06e334",
   "metadata": {},
   "source": [
    "Remove highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a441524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed columns:  53\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = X.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find features with correlation greater than 0.9\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "print(\"Removed columns: \", len(to_drop))\n",
    "# Drop features \n",
    "X.drop(to_drop, axis=1, inplace=True)\n",
    "X_test.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3788f36",
   "metadata": {},
   "source": [
    "Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9abc021",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = RobustScaler()\n",
    "X = transformer.fit_transform(X)\n",
    "X_test = transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8c0cbc",
   "metadata": {},
   "source": [
    "Impute median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d131c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_median = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "X = imp_median.fit_transform(X)\n",
    "X_test = imp_median.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "54fcfce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07655df4",
   "metadata": {},
   "source": [
    "Feature selection with Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39ec702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_select(train, val, target, alpha=1):\n",
    "    \n",
    "    clf = Lasso(alpha=alpha)\n",
    "    clf.fit(train, target)\n",
    "    coef = clf.coef_\n",
    "    \n",
    "    # select features with non-zero lasso coefficients\n",
    "    \n",
    "    train = train[:, coef != 0]\n",
    "    val = val[:, coef != 0]\n",
    "    print(\"Selected features: \" ,np.count_nonzero(clf.coef_))\n",
    "    \n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed7c8e5",
   "metadata": {},
   "source": [
    "Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9dc4961e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:  20\n"
     ]
    }
   ],
   "source": [
    "X_s, X_test_s = lasso_select(X, X_test, y, alpha=0.56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f9b50c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers removed:  68\n"
     ]
    }
   ],
   "source": [
    "dbscan = DBSCAN(eps=4.9, min_samples=40)\n",
    "dbscan.fit(X_s)\n",
    "X_t = X_s[dbscan.labels_ != -1]\n",
    "y_t = y[dbscan.labels_ != -1]\n",
    "print(\"Outliers removed: \", (dbscan.labels_ == -1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b7630dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.concatenate((X_t, np.expand_dims(y_t, axis=-1)), axis=1)\n",
    "dataset = torch.from_numpy(dataset).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8e6f5f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.l1 = nn.Linear(20, 5)\n",
    "        self.l2 = nn.Linear(5, 1)\n",
    "        self.l3 = nn.Linear(20, 1)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        z = self.l1(x)\n",
    "        z = self.relu(z)\n",
    "        z = self.l2(z)\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2010c343",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f7717e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsize = int(0.8*X_t.shape[0])\n",
    "valsize = X_t.shape[0] - trainsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "870af421",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = random_split(dataset, [trainsize, valsize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "dea99662",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train, batch_size=4)\n",
    "validloader = DataLoader(val, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "91ed5f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "metric = R2Score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "061d6989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train R2: -55.5419 |  Duration 0.29 sec\n",
      "Epoch 20 | Train R2: -16.6339 |  Duration 0.26 sec\n",
      "Epoch 40 | Train R2: -5.2368 |  Duration 0.26 sec\n",
      "Epoch 60 | Train R2: -0.8248 |  Duration 0.27 sec\n",
      "Epoch 80 | Train R2: 0.0741 |  Duration 0.27 sec\n",
      "Epoch 100 | Train R2: 0.2074 |  Duration 0.27 sec\n",
      "Epoch 120 | Train R2: 0.2379 |  Duration 0.30 sec\n",
      "Epoch 140 | Train R2: 0.2475 |  Duration 0.27 sec\n",
      "Epoch 160 | Train R2: 0.2526 |  Duration 0.30 sec\n",
      "Epoch 180 | Train R2: 0.2561 |  Duration 0.31 sec\n",
      "Epoch 200 | Train R2: 0.2587 |  Duration 0.26 sec\n",
      "Epoch 220 | Train R2: 0.2606 |  Duration 0.28 sec\n",
      "Epoch 240 | Train R2: 0.2635 |  Duration 0.27 sec\n",
      "Epoch 260 | Train R2: 0.2651 |  Duration 0.28 sec\n",
      "Epoch 280 | Train R2: 0.2661 |  Duration 0.27 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [173]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m t \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      7\u001b[0m metric\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m trainloader:\n\u001b[0;32m     11\u001b[0m     x \u001b[38;5;241m=\u001b[39m batch[:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     12\u001b[0m     y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqueeze(batch[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytcu10\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:527\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 527\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_name):\n\u001b[0;32m    528\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytcu10\\lib\\site-packages\\torch\\autograd\\profiler.py:436\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_enter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 800\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    t = time.time()\n",
    "    \n",
    "    metric.reset()\n",
    "    \n",
    "    for batch in trainloader:\n",
    "        \n",
    "        x = batch[:,:-1]\n",
    "        y = torch.squeeze(batch[:,-1])\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        model.train()\n",
    "        \n",
    "        out = model(x)\n",
    "        \n",
    "        loss = criterion(y, out)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optim.step()\n",
    "        \n",
    "        metric.update((torch.squeeze(out), y))\n",
    "\n",
    "    r2 = metric.compute()\n",
    "        \n",
    "    epoch_duration = time.time() - t\n",
    "        \n",
    "    if e % 20 == 0:\n",
    "        print(f'Epoch {e} | Train R2: {r2:.4f} | '\n",
    "              # f' Validation R2: {r2_val:.4f} | '\n",
    "              f' Duration {epoch_duration:.2f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85e1d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d9035e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e358de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
