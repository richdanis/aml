{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lazypredict\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_X_last = pd.read_csv(\"data/X_train_features.csv\", index_col=0)\n",
    "df_X_richard = pd.read_csv(\"data/template_features.csv\", index_col=0)\n",
    "df_X_tim = pd.read_csv(\"full_waveform_features.csv\", index_col=0)\n",
    "df_X_pyHRV = pd.read_csv(\"data/pyHRV_features.csv\", index_col=0)\n",
    "df_X_hrv_analysis = pd.read_csv(\"data/hrv-analysis_features.csv\")\n",
    "df_X = pd.concat((df_X_tim,df_X_richard),axis=1)\n",
    "df_X = pd.concat((df_X, df_X_pyHRV),axis=1)\n",
    "df_X = pd.concat((df_X, df_X_hrv_analysis),axis=1)\n",
    "# df_X = pd.concat((df_X, df_X_last),axis=1)\n",
    "df_Y = pd.read_csv(\"data/Y_train.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_corr(X):\n",
    "    corr_matrix = X.corr().abs()\n",
    "\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "    # Find features with correlation greater than 0.9\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "    print(\"Removed columns: \", len(to_drop))\n",
    "    # Drop features \n",
    "    X.drop(to_drop, axis=1, inplace=True)\n",
    "    #X_test.drop(to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed columns:  31\n"
     ]
    }
   ],
   "source": [
    "df_X = rm_corr(df_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "transformer = RobustScaler()\n",
    "X = transformer.fit_transform(df_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5117, 93)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_median = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "X = imp_median.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5117, 80)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = SelectKBest(f_classif, k=80).fit_transform(X, df_Y)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████▏  | 28/29 [00:35<00:01,  1.54s/it]"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, df_Y,stratify=df_Y,test_size=.5,random_state=0)\n",
    "clf = LazyClassifier(verbose=0, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB, LGBM, RandomForestClassifier, ExtraTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5117, 22)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_hsv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "b72a1a9fcdc4a37b876d59b8fde098d6bda68dcbb49ecf7e0339451022590265"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
