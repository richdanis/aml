{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import lazypredict\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm\n",
    "import xgboost\n",
    "import sklearn\n",
    "import catboost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import IsolationForest\n",
    "#from pyod.models.ecod import ECOD\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_last = pd.read_csv(\"data/X_train_features.csv\", index_col=0)\n",
    "df_X_richard = pd.read_csv(\"data/template_features_v4.csv\", index_col=0)\n",
    "df_X_tim = pd.read_csv(\"data/full_waveform_features.csv\", index_col=0)\n",
    "df_X_pyHRV = pd.read_csv(\"data/pyHRV_features.csv\", index_col=0)\n",
    "df_X_hrv_analysis = pd.read_csv(\"data/hrv-analysis_features.csv\", index_col=0)\n",
    "df_X = pd.concat((df_X_tim,df_X_richard,df_X_pyHRV,df_X_hrv_analysis),axis=1)\n",
    "df_Y = pd.read_csv(\"data/y_train.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_corr(X):\n",
    "    corr_matrix = X.corr().abs()\n",
    "\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "    # Find features with correlation greater than 0.9\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "    print(\"Removed columns: \", len(to_drop))\n",
    "    # Drop features \n",
    "    X.drop(to_drop, axis=1, inplace=True)\n",
    "    # X_test.drop(to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed columns:  52\n"
     ]
    }
   ],
   "source": [
    "df_X = rm_corr(df_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "transformer = RobustScaler()\n",
    "X = transformer.fit_transform(df_X)\n",
    "# nans are no problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_median = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "X = imp_median.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5117, 93)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Outlier Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n",
      "45\n",
      "148\n"
     ]
    }
   ],
   "source": [
    "Y = df_Y.to_numpy()\n",
    "for i in range(3):\n",
    "    class_i = np.squeeze(Y==i)\n",
    "    ids = np.where(class_i)[0]\n",
    "    X_c = X[class_i]\n",
    "    # preds = IsolationForest(random_state=0, contamination = 0.06).fit_predict(X_c)\n",
    "    clf = ECOD()\n",
    "    clf.fit(X_c)\n",
    "    preds = clf.predict(X_c)\n",
    "    outlier_ids = ids[preds == 1] # minus 1 for isolation forest\n",
    "    Y = np.delete(Y, outlier_ids, axis=0)\n",
    "    X = np.delete(X, outlier_ids, axis=0)\n",
    "    print(outlier_ids.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5117, 93)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = SelectKBest(f_classif, k=70).fit_transform(X, df_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'tuple' object has no attribute '__name__'\n",
      "Invalid Classifier(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [00:16<00:00,  4.13s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.74</td>\n",
       "      <td>None</td>\n",
       "      <td>0.83</td>\n",
       "      <td>7.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.74</td>\n",
       "      <td>None</td>\n",
       "      <td>0.84</td>\n",
       "      <td>5.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.67</td>\n",
       "      <td>None</td>\n",
       "      <td>0.82</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.66</td>\n",
       "      <td>None</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy  Balanced Accuracy ROC AUC  F1 Score  \\\n",
       "Model                                                                   \n",
       "XGBClassifier               0.83               0.74    None      0.83   \n",
       "LGBMClassifier              0.84               0.74    None      0.84   \n",
       "RandomForestClassifier      0.82               0.67    None      0.82   \n",
       "ExtraTreesClassifier        0.81               0.66    None      0.81   \n",
       "\n",
       "                        Time Taken  \n",
       "Model                               \n",
       "XGBClassifier                 7.58  \n",
       "LGBMClassifier                5.13  \n",
       "RandomForestClassifier        2.88  \n",
       "ExtraTreesClassifier          0.92  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, df_Y,test_size=.5)\n",
    "classifiers = [(\"LGBMClassifier\", lightgbm.LGBMClassifier), (\"XGBClassifier\", xgboost.XGBClassifier), \\\n",
    "               (\"RandomForestClassifier\", sklearn.ensemble.RandomForestClassifier), \\\n",
    "                (\"ExtraTreesClassifier\", sklearn.ensemble.ExtraTreesClassifier)]\n",
    "# catboost classifier takes very long but is similar in performance to these other classifiers\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None, classifiers=classifiers)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_Y.to_numpy()\n",
    "last = df_X_last.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "f1_last = []\n",
    "f1_ours = []\n",
    "for train_index, test_index in skf.split(X, Y):\n",
    "    clf = xgboost.XGBClassifier()\n",
    "    \n",
    "    clf.fit(X[train_index], Y[train_index])\n",
    "    y_pred = clf.predict(X[test_index])\n",
    "    f1_ours.append(f1_score(Y[test_index], y_pred, average='micro'))\n",
    "    \n",
    "    clf.fit(last[train_index], Y[train_index])\n",
    "    y_pred = clf.predict(last[test_index])\n",
    "    f1_last.append(f1_score(Y[test_index], y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ours | Average:  0.829394626710655 Std:  0.008750962139280984\n",
      "Theirs | Average:  0.8458077498778105 Std:  0.01066281107735506\n"
     ]
    }
   ],
   "source": [
    "# old feature version\n",
    "print(\"Ours | Average: \", np.mean(f1_ours), \"Std: \", np.std(f1_ours))\n",
    "print(\"Theirs | Average: \", np.mean(f1_last), \"Std: \", np.std(f1_last))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "b72a1a9fcdc4a37b876d59b8fde098d6bda68dcbb49ecf7e0339451022590265"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
