{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import lazypredict\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm\n",
    "import xgboost\n",
    "import sklearn\n",
    "import catboost\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import IsolationForest\n",
    "#from pyod.models.ecod import ECOD\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_last = pd.read_csv(\"data/X_train_features.csv\", index_col=0)\n",
    "# df_X = pd.read_csv(\"data/X_train_features_new.csv\", index_col=0)\n",
    "df_X = pd.read_csv(\"data/X_train_features_knn_200.csv\", index_col=0)\n",
    "df_Y = pd.read_csv(\"data/y_train.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_corr(X):\n",
    "    corr_matrix = X.corr().abs()\n",
    "\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "    # Find features with correlation greater than 0.9\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "    print(\"Removed columns: \", len(to_drop))\n",
    "    # Drop features \n",
    "    X.drop(to_drop, axis=1, inplace=True)\n",
    "    # X_test.drop(to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed columns:  19\n"
     ]
    }
   ],
   "source": [
    "df_X = rm_corr(df_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "transformer = RobustScaler()\n",
    "X = transformer.fit_transform(df_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=200)\n",
    "#imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "X = imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5117, 204)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Outlier Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n",
      "45\n",
      "148\n"
     ]
    }
   ],
   "source": [
    "Y = df_Y.to_numpy()\n",
    "for i in range(3):\n",
    "    class_i = np.squeeze(Y==i)\n",
    "    ids = np.where(class_i)[0]\n",
    "    X_c = X[class_i]\n",
    "    # preds = IsolationForest(random_state=0, contamination = 0.06).fit_predict(X_c)\n",
    "    clf = ECOD()\n",
    "    clf.fit(X_c)\n",
    "    preds = clf.predict(X_c)\n",
    "    outlier_ids = ids[preds == 1] # minus 1 for isolation forest\n",
    "    Y = np.delete(Y, outlier_ids, axis=0)\n",
    "    X = np.delete(X, outlier_ids, axis=0)\n",
    "    print(outlier_ids.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5117, 111)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = SelectKBest(f_classif, k=170).fit_transform(X, df_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:36<00:00,  1.25s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.76</td>\n",
       "      <td>None</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.74</td>\n",
       "      <td>None</td>\n",
       "      <td>0.83</td>\n",
       "      <td>4.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.74</td>\n",
       "      <td>None</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.73</td>\n",
       "      <td>None</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.72</td>\n",
       "      <td>None</td>\n",
       "      <td>0.82</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.72</td>\n",
       "      <td>None</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.72</td>\n",
       "      <td>None</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.72</td>\n",
       "      <td>None</td>\n",
       "      <td>0.83</td>\n",
       "      <td>2.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.72</td>\n",
       "      <td>None</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>None</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.71</td>\n",
       "      <td>None</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.71</td>\n",
       "      <td>None</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.70</td>\n",
       "      <td>None</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.69</td>\n",
       "      <td>None</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.69</td>\n",
       "      <td>None</td>\n",
       "      <td>0.81</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.67</td>\n",
       "      <td>None</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.67</td>\n",
       "      <td>None</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.66</td>\n",
       "      <td>None</td>\n",
       "      <td>0.81</td>\n",
       "      <td>10.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.66</td>\n",
       "      <td>None</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.63</td>\n",
       "      <td>None</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.62</td>\n",
       "      <td>None</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.59</td>\n",
       "      <td>None</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.54</td>\n",
       "      <td>None</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelSpreading</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.48</td>\n",
       "      <td>None</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.48</td>\n",
       "      <td>None</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.25</td>\n",
       "      <td>None</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy ROC AUC  F1 Score  \\\n",
       "Model                                                                          \n",
       "LinearDiscriminantAnalysis         0.82               0.76    None      0.82   \n",
       "XGBClassifier                      0.84               0.74    None      0.83   \n",
       "LGBMClassifier                     0.84               0.74    None      0.84   \n",
       "GaussianNB                         0.76               0.73    None      0.75   \n",
       "LinearSVC                          0.82               0.72    None      0.82   \n",
       "LogisticRegression                 0.82               0.72    None      0.82   \n",
       "NearestCentroid                    0.75               0.72    None      0.74   \n",
       "RandomForestClassifier             0.84               0.72    None      0.83   \n",
       "SVC                                0.83               0.72    None      0.83   \n",
       "BernoulliNB                        0.72               0.72    None      0.72   \n",
       "SGDClassifier                      0.81               0.71    None      0.80   \n",
       "ExtraTreesClassifier               0.83               0.71    None      0.83   \n",
       "RidgeClassifierCV                  0.82               0.70    None      0.81   \n",
       "RidgeClassifier                    0.82               0.69    None      0.81   \n",
       "BaggingClassifier                  0.81               0.69    None      0.81   \n",
       "Perceptron                         0.80               0.67    None      0.80   \n",
       "AdaBoostClassifier                 0.77               0.67    None      0.76   \n",
       "CalibratedClassifierCV             0.82               0.66    None      0.81   \n",
       "KNeighborsClassifier               0.80               0.66    None      0.79   \n",
       "PassiveAggressiveClassifier        0.79               0.63    None      0.79   \n",
       "DecisionTreeClassifier             0.76               0.62    None      0.76   \n",
       "ExtraTreeClassifier                0.72               0.59    None      0.72   \n",
       "QuadraticDiscriminantAnalysis      0.75               0.54    None      0.73   \n",
       "LabelSpreading                     0.72               0.48    None      0.70   \n",
       "LabelPropagation                   0.72               0.48    None      0.70   \n",
       "DummyClassifier                    0.60               0.25    None      0.45   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "LinearDiscriminantAnalysis           0.13  \n",
       "XGBClassifier                        4.97  \n",
       "LGBMClassifier                       2.93  \n",
       "GaussianNB                           0.07  \n",
       "LinearSVC                            2.50  \n",
       "LogisticRegression                   0.19  \n",
       "NearestCentroid                      0.04  \n",
       "RandomForestClassifier               2.98  \n",
       "SVC                                  1.17  \n",
       "BernoulliNB                          0.05  \n",
       "SGDClassifier                        0.25  \n",
       "ExtraTreesClassifier                 0.97  \n",
       "RidgeClassifierCV                    0.11  \n",
       "RidgeClassifier                      0.05  \n",
       "BaggingClassifier                    2.99  \n",
       "Perceptron                           0.08  \n",
       "AdaBoostClassifier                   1.75  \n",
       "CalibratedClassifierCV              10.43  \n",
       "KNeighborsClassifier                 0.34  \n",
       "PassiveAggressiveClassifier          0.11  \n",
       "DecisionTreeClassifier               0.58  \n",
       "ExtraTreeClassifier                  0.05  \n",
       "QuadraticDiscriminantAnalysis        0.10  \n",
       "LabelSpreading                       1.74  \n",
       "LabelPropagation                     1.66  \n",
       "DummyClassifier                      0.04  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, df_Y,test_size=.5)\n",
    "\n",
    "classifiers = [(\"LGBMClassifier\", lightgbm.LGBMClassifier), (\"XGBClassifier\", xgboost.XGBClassifier), \\\n",
    "               (\"RandomForestClassifier\", sklearn.ensemble.RandomForestClassifier), \\\n",
    "                (\"ExtraTreesClassifier\", sklearn.ensemble.ExtraTreesClassifier)]\n",
    "# catboost classifier takes very long but is similar in performance to these other classifiers\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None) # classifiers=classifiers\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_Y.to_numpy()\n",
    "last = df_X_last.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "f1_last = []\n",
    "f1_ours = []\n",
    "\n",
    "clf1 = xgboost.XGBClassifier()\n",
    "clf2 = RandomForestClassifier()\n",
    "clf3 = lightgbm.LGBMClassifier()\n",
    "\n",
    "for train_index, test_index in skf.split(X, Y):\n",
    "    clf = xgboost.XGBClassifier()\n",
    "    \n",
    "    eclf1 = VotingClassifier(estimators=[\n",
    "    ('xgb', clf1), ('rf', clf2), ('lgbm', clf3)], voting='hard')\n",
    "    \n",
    "    eclf1.fit(X[train_index], Y[train_index])\n",
    "    y_pred = eclf1.predict(X[test_index])\n",
    "    f1_ours.append(f1_score(Y[test_index], y_pred, average='micro'))\n",
    "    \n",
    "    clf.fit(last[train_index], Y[train_index])\n",
    "    y_pred = clf.predict(last[test_index])\n",
    "    f1_last.append(f1_score(Y[test_index], y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ours | Average:  0.8465907181695993 Std:  0.0045519911937564415\n",
      "Theirs | Average:  0.8458077498778105 Std:  0.01066281107735506\n"
     ]
    }
   ],
   "source": [
    "# voting classifier\n",
    "print(\"Ours | Average: \", np.mean(f1_ours), \"Std: \", np.std(f1_ours))\n",
    "print(\"Theirs | Average: \", np.mean(f1_last), \"Std: \", np.std(f1_last))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ours | Average:  0.840141396322092 Std:  0.006176959267631727\n",
      "Theirs | Average:  0.8458077498778105 Std:  0.01066281107735506\n"
     ]
    }
   ],
   "source": [
    "# xgb\n",
    "print(\"Ours | Average: \", np.mean(f1_ours), \"Std: \", np.std(f1_ours))\n",
    "print(\"Theirs | Average: \", np.mean(f1_last), \"Std: \", np.std(f1_last))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "b72a1a9fcdc4a37b876d59b8fde098d6bda68dcbb49ecf7e0339451022590265"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
